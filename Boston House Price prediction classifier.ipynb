{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Boston_catg.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98   Low  \n",
       "1  396.90   9.14   Low  \n",
       "2  392.83   4.03  High  \n",
       "3  394.63   2.94  High  \n",
       "4  396.90    NaN  High  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       20\n",
       "ZN         20\n",
       "INDUS      20\n",
       "CHAS       20\n",
       "NOX         0\n",
       "RM          0\n",
       "AGE        20\n",
       "DIS         0\n",
       "RAD         0\n",
       "TAX         0\n",
       "PTRATIO     0\n",
       "B           0\n",
       "LSTAT      20\n",
       "MEDV        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS       float64\n",
       "NOX        float64\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD          int64\n",
       "TAX          int64\n",
       "PTRATIO    float64\n",
       "B          float64\n",
       "LSTAT      float64\n",
       "MEDV        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSeries=df.dtypes   \n",
    "dataSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02731, 0.0, 0.0, 0.0, 0.46, 3.26, 0.0, 1.28, 0, 0, 0.0, 0, 0.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding the values of medv column \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode = LabelEncoder()\n",
    "\n",
    "df.MEDV = encode.fit_transform(df.MEDV)\n",
    "\n",
    "# displaying the data set to check the encoded values \n",
    "df.head()\n",
    "\n",
    "[0.02731,0.0,0.00,0.0,0.46,3.26,00.0,1.28,0,0,00.0,0,0.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    275\n",
       "0    119\n",
       "Name: MEDV, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking class imbalance\n",
    "df['MEDV'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6979695431472082"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_imbalance=275/(275+119)\n",
    "class_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the target and independent variable\n",
    "\n",
    "X= df.drop(['MEDV'], axis = 1)\n",
    "y= df['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (275, 13)\n",
      "Shape of X_test:  (119, 13)\n",
      "Shape of y_train:  (275,)\n",
      "Shape of y_test (119,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: \",X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \",y_train.shape)\n",
    "print(\"Shape of y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224    0\n",
       "420    1\n",
       "101    0\n",
       "86     1\n",
       "468    1\n",
       "      ..\n",
       "484    1\n",
       "408    1\n",
       "178    0\n",
       "410    1\n",
       "164    1\n",
       "Name: MEDV, Length: 275, dtype: int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the object of the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression()\n",
    "\n",
    "model1.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    pred1 = model1.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values on Test Data [1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1\n",
      " 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1\n",
      " 1 1 1 0 1 0 0 1]\n",
      "Logistic Regression Train Score:  0.9018181818181819\n",
      "Logistic Regression Test Score:  0.9243697478991597\n",
      "Accuracy Score on test data : 0.9243697478991597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Predicted Values on Test Data',(pred1))\n",
    "\n",
    "print('Logistic Regression Train Score: ',model1.score(X_train_std, y_train))\n",
    "print('Logistic Regression Test Score: ',model1.score(X_test_std, y_test))\n",
    "\n",
    "print('Accuracy Score on test data :',accuracy_score(y_test,pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix \n",
    "A confusion matrix is an N X N matrix, where N is the number of classes being predicted. \n",
    "Confusion Matrix gives us a matrix as output and describes the complete performance of the model.\n",
    "\n",
    "The correct predictions falls on the diagonal line of the matrix.\n",
    "\n",
    "4 important terms in Confusion Matrix:\n",
    "\n",
    "True Positives : The cases in which we predicted YES and the actual output was also YES.\n",
    "\n",
    "False Negatives(Type 2 error) : The cases in which we predicted NO and the actual output was YES.\n",
    "\n",
    "False Positives(Type 1 error) : The cases in which we predicted YES and the actual output was NO.\n",
    "\n",
    "True Negatives : The cases in which we predicted NO and the actual output was NO.\n",
    "\n",
    "The Confusion matrix in itself is not a performance measure as such,\n",
    "but almost all of the performance metrics are based on Confusion Matrix and the numbers inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  6]\n",
      " [ 3 78]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,pred1)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Positive  Negative\n",
      "Positive        32         6\n",
      "Negative         3        78\n",
      "Accuracy through Logistic regression : 0.9243697478991597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np \n",
    "cm=np.array(confusion_matrix(y_test,pred1))\n",
    "df_confusion=pd.DataFrame(cm,index=[\"Positive\",\"Negative\"], columns=[\"Positive\",\"Negative\"])\n",
    "print(df_confusion)\n",
    "print('Accuracy through Logistic regression :',accuracy_score(y_test,pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is telling us that we have 32+78 correct predictions and 3+6 incorrect predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector Machine  when kernel is random = rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#create a classifier\n",
    "Model2 = svm.SVC()\n",
    "\n",
    "#train the model\n",
    "Model2.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the response\n",
    "pred2 = Model2.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values on Test Data [1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1\n",
      " 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1\n",
      " 1 1 1 0 1 0 1 1]\n",
      "SVM Train Score with RBF kernel:  0.92\n",
      "SVM Test Score with RBF kernel:  0.8991596638655462\n",
      "Model Accuracy through SVM: 0.8991596638655462\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Predicted Values on Test Data',(pred2))\n",
    "\n",
    "print('SVM Train Score with RBF kernel: ',Model2.score(X_train_std, y_train))\n",
    "print('SVM Test Score with RBF kernel: ',Model2.score(X_test_std, y_test))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "#accuracy\n",
    "print(\"Model Accuracy through SVM:\", metrics.accuracy_score(y_test,y_pred=pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  9]\n",
      " [ 3 78]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test,pred2)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Positive  Negative\n",
      "Positive        29         9\n",
      "Negative         3        78\n",
      "Accuracy through SVM RBF : 0.8991596638655462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np \n",
    "cm=np.array(confusion_matrix(y_test,pred2))\n",
    "df_confusion=pd.DataFrame(cm,index=[\"Positive\",\"Negative\"], columns=[\"Positive\",\"Negative\"])\n",
    "print(df_confusion)\n",
    "print('Accuracy through SVM RBF :',accuracy_score(y_test,pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is telling us that we have 29+78 correct predictions and 3+9 incorrect predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine with kernel linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#create a classifier\n",
    "Model3 = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "#train the model\n",
    "Model3.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the response\n",
    "pred3 = Model3.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values on Test Data [1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1\n",
      " 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1\n",
      " 1 1 1 0 1 0 0 1]\n",
      "SVM Train Score with linear kernel :  0.9054545454545454\n",
      "SVM Regression Test Score with linear kernel:  0.8991596638655462\n",
      "Model Accuracy through SVM with linear kernel: 0.8991596638655462\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Predicted Values on Test Data',(pred3))\n",
    "\n",
    "print('SVM Train Score with linear kernel : ',Model3.score(X_train_std, y_train))\n",
    "print('SVM Regression Test Score with linear kernel: ',Model3.score(X_test_std, y_test))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "#accuracy\n",
    "print(\"Model Accuracy through SVM with linear kernel:\", metrics.accuracy_score(y_test,y_pred=pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  7]\n",
      " [ 5 76]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,pred3)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Positive  Negative\n",
      "Positive        31         7\n",
      "Negative         5        76\n",
      "Accuracy through SVM Linear : 0.8991596638655462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np \n",
    "cm=np.array(confusion_matrix(y_test,pred3))\n",
    "df_confusion=pd.DataFrame(cm,index=[\"Positive\",\"Negative\"], columns=[\"Positive\",\"Negative\"])\n",
    "print(df_confusion)\n",
    "print('Accuracy through SVM Linear :',accuracy_score(y_test,pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is telling us that we have 31+76  correct predictions and 7+5 incorrect predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate model : Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crime rate, Pollution, DIS,Rooms, Budget = 20k $\n",
    "Working_Professional = [0.02731,0.0,0.00,0.0,0.46,0.00,00.0,0.00,0,0,00.0,0,0.00], \n",
    "\n",
    "value = model1.predict(Working_Professional)\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crime rate, PTRATIO, number of room, budget = 30k $\n",
    "Rich_couple = [4,0.0,0.00,0.0,0.0,6,0.00,0.00,0,0,25,0,0.00], \n",
    "\n",
    "value = model1.predict(Rich_couple)\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
